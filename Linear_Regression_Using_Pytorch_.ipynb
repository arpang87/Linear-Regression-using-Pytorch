{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression Using Pytorch .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD0SWB_tPvhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the library \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQU07Y3xP5lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Reading the dataset\n",
        "X, y = load_boston(return_X_y=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urf6UF2lQL0v",
        "colab_type": "code",
        "outputId": "b5d8b1bc-bc5f-4565-cd67-8a9d5f73df89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###Looking at shape \n",
        "X.shape"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTnxfKO4QNaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c14b5c52-2262-48aa-a119-4ab78814bf7e"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdHRrSXGQR54",
        "colab_type": "code",
        "outputId": "cfb709f6-6546-41dc-90df-cb835590d8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "##Looking at y distribution\n",
        "plt.hist(target)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 21.,  55.,  82., 154.,  84.,  41.,  30.,   8.,  10.,  21.]),\n",
              " array([ 5. ,  9.5, 14. , 18.5, 23. , 27.5, 32. , 36.5, 41. , 45.5, 50. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD6CAYAAABamQdMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqQ4S5JDfo/hypf4c2Iae8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lllpp1PPQUsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=torch.from_numpy(X)\n",
        "y=torch.from_numpy(y)\n",
        "X=X.float()\n",
        "y=y.float()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upsFXcz1Q9pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TensorDataset allows to get rows from X and Y as tuples.\n",
        "#DataLoader split the data into batches while training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GkrcQGcQscw",
        "colab_type": "code",
        "outputId": "c924bade-943e-4be4-9bcd-cb326ff0506a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "df = TensorDataset(X, y)\n",
        "df[0:3]"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
              "          6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
              "          4.9800e+00],\n",
              "         [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 6.4210e+00,\n",
              "          7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9690e+02,\n",
              "          9.1400e+00],\n",
              "         [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 7.1850e+00,\n",
              "          6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9283e+02,\n",
              "          4.0300e+00]]), tensor([24.0000, 21.6000, 34.7000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1j0ottzQ5Vx",
        "colab_type": "code",
        "outputId": "e07d2a6b-a8c6-416f-e35e-af36d355a9fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "batchsize = 5\n",
        "df = DataLoader(df, batchsize, shuffle=True)\n",
        "next(iter(df))"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[6.2110e-02, 4.0000e+01, 1.2500e+00, 0.0000e+00, 4.2900e-01, 6.4900e+00,\n",
              "          4.4400e+01, 8.7921e+00, 1.0000e+00, 3.3500e+02, 1.9700e+01, 3.9690e+02,\n",
              "          5.9800e+00],\n",
              "         [1.4438e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.9700e-01, 6.8520e+00,\n",
              "          1.0000e+02, 1.4655e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 1.7936e+02,\n",
              "          1.9780e+01],\n",
              "         [3.8497e+00, 0.0000e+00, 1.8100e+01, 1.0000e+00, 7.7000e-01, 6.3950e+00,\n",
              "          9.1000e+01, 2.5052e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9134e+02,\n",
              "          1.3270e+01],\n",
              "         [2.1492e+00, 0.0000e+00, 1.9580e+01, 0.0000e+00, 8.7100e-01, 5.7090e+00,\n",
              "          9.8500e+01, 1.6232e+00, 5.0000e+00, 4.0300e+02, 1.4700e+01, 2.6195e+02,\n",
              "          1.5790e+01],\n",
              "         [1.3880e+00, 0.0000e+00, 8.1400e+00, 0.0000e+00, 5.3800e-01, 5.9500e+00,\n",
              "          8.2000e+01, 3.9900e+00, 4.0000e+00, 3.0700e+02, 2.1000e+01, 2.3260e+02,\n",
              "          2.7710e+01]]), tensor([22.9000, 27.5000, 21.7000, 19.4000, 13.2000])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64IDWiMERTKR",
        "colab_type": "code",
        "outputId": "036961b1-9ffa-4977-f242-506ce3896b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Defining the regression model\n",
        "model = nn.Linear(13,1)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0431, -0.0619, -0.0038,  0.2055, -0.1150, -0.1098,  0.0169,  0.0512,\n",
            "          0.2727,  0.0249, -0.2294, -0.1087, -0.0365]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1727], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7-vUp23RcTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the SGD optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrtiAKXqRkSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL5zdJAZRvha",
        "colab_type": "code",
        "outputId": "e1036075-98ff-416f-e7d0-4fd71dc4b616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "loss = loss_fn(model(X), y)\n",
        "print(loss)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3165.7556, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Using a target size (torch.Size([506])) that is different to the input size (torch.Size([506, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ntGB3CaR0B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining  utility function for  model training\n",
        "def model_fit(num_epochs, model, loss_fn, opt):\n",
        "    for epoch in range(num_epochs):\n",
        "        for x_var,y_var in df:\n",
        "            # Generating the  predictions from the model\n",
        "            predictions = model(x_var)\n",
        "            loss = loss_fn(predictions, y_var)\n",
        "            # Performing  SGD\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        print('Training loss: ', loss_fn(model(X), y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVjZ2j3rUChZ",
        "colab_type": "code",
        "outputId": "b74a9569-8965-4eb1-e9c7-5bdebbe72594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training  the model for 50 epochs\n",
        "model_fit(100, model, loss_fn, opt)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Using a target size (torch.Size([506])) that is different to the input size (torch.Size([506, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss:  tensor(263.6963, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(162.9927, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(128.9978, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(114.4925, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(113.7887, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.2338, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(110.6692, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(113.4122, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.5962, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(112.8768, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(111.1895, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(110.6148, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.4210, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.7613, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.6420, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.5554, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.5121, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.0960, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.7353, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.6096, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.1501, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.4417, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.3002, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(114.6393, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.3426, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.3145, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.0625, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.0342, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.0160, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.5952, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.0237, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.1923, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.7732, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.2236, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.9002, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.2801, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.3638, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.1006, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.3268, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.9001, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(110.4040, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.7549, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.7956, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.3465, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.7686, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(114.3857, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.9602, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.0708, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.2376, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.7742, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.6519, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.5600, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.4966, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.4350, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.2622, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(108.3917, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.2784, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.2465, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.1619, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.3032, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.9926, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.4361, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.8743, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(110.2613, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.2020, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.2716, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.4616, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.8659, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(109.2370, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.6815, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.5812, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.5865, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.8315, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.5981, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(110.2639, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.4109, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.1661, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(111.9901, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.0213, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.5564, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.1985, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.2475, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(110.2459, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.2108, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.9247, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(104.8848, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.1400, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(104.8621, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.7878, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(104.8816, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.5776, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.1943, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.0440, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.2933, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(106.3397, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.4248, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(107.0549, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(104.7924, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(104.7767, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(105.1699, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTBzdc7UKY_",
        "colab_type": "code",
        "outputId": "3c45ce7b-0b21-481d-ef0d-77582072ae2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Generate predictions\n",
        "predictions = model(X)\n",
        "predictions[0:3]"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[21.7955],\n",
              "        [21.3012],\n",
              "        [20.4461]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZLeOj6gcvVf",
        "colab_type": "code",
        "outputId": "f525ec4b-41d1-481b-afa9-88bea40241e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y[0:3],predictions[0:3]"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.0000, 21.6000, 34.7000]), tensor([[21.7955],\n",
              "         [21.3012],\n",
              "         [20.4461]], grad_fn=<SliceBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QzoiVXpc4pR",
        "colab_type": "code",
        "outputId": "20e9f72f-8bb4-4dee-b2ba-8dba2d06e2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "err=y-predictions\n",
        "rmse=torch.sqrt(torch.sum(err**2)/err.numel())\n",
        "rmse"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.2552, grad_fn=<SqrtBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPNnvvYrq_ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}